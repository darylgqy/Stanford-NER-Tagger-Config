  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Stanford NER\n",
    "\n",
    "```python\n",
    "#import packages\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.chunk import conlltags2tree\n",
    "from nltk.tree import Tree\n",
    "```\n",
    "Please find the correct type of files for the paths and add an r (raw string literal) before the quotation marks in the paths.\n",
    "```python\n",
    "#Configurations for py-java and setting paths for stanfordNERTagger\n",
    "import os\n",
    "java_path = r\"C:/Program Files/Java/jre1.8.0_144/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "\n",
    "stanford_ner_path = r\"C:/Users/Daryl/Desktop/Stanford NER/stanford-ner-2018-02-27/stanford-ner-2018-02-27/stanford-ner-3.9.1.jar\"\n",
    "stanford_classifier = r\"C:/Users/Daryl/Desktop/Stanford NER/stanford-ner-2018-02-27/stanford-ner-2018-02-27/classifiers/english.all.3class.distsim.crf.ser.gz\"\n",
    "```\n",
    "\n",
    "### Methods\n",
    "\n",
    "```python\n",
    "#Process and tokenize the words in the text file\n",
    "def process_text(text_file):\n",
    "    text = open(text_file,errors = \"ignore\")\n",
    "    text = text.read()\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    return tokenized_text\n",
    "```\n",
    "\n",
    "```python\n",
    "#Create a Stanford NER Tagger object and use to tag each tokenized word\n",
    "def stanford_tagger(tokenized_text):\n",
    "    #create tagger \n",
    "    st = StanfordNERTagger(stanford_classifier, stanford_ner_path, encoding='utf-8')\n",
    "    #tag every tokenized word\n",
    "    classified_text = st.tag(tokenized_text)\n",
    "    return classified_text\n",
    "```\n",
    "\n",
    "```python\n",
    "#Tag tokens with standard NLP BIO tags\n",
    "def bio_tagger(classified_text):\n",
    "    bio_tagged = []\n",
    "    prev_tag = \"O\"\n",
    "    for token, tag in classified_text:\n",
    "        if tag == \"O\": #O\n",
    "            bio_tagged.append((token,tag))\n",
    "            prev_tag = tag\n",
    "            continue\n",
    "        if tag != \"O\" and prev_tag == \"O\": #Begin NE\n",
    "            bio_tagged.append((token, \"B-\" + tag))\n",
    "            prev_tag = tag\n",
    "        elif prev_tag != \"O\" and prev_tag == tag: #Inside NE\n",
    "            bio_tagged.append((token, \"I-\" + tag))\n",
    "            prev_tag = tag\n",
    "        elif prev_tag != \"O\" and prev_tag != tag: #Adjacent NE\n",
    "            bio_tagged.append((token, \"B-\" + tag))\n",
    "            prev_tag = tag\n",
    "    return bio_tagged\n",
    "```\n",
    "\n",
    "```python\n",
    "#Create Chunk Tree\n",
    "def stanford_tree(bio_tagged):\n",
    "    tokens, ne_tags = zip(*bio_tagged)\n",
    "    pos_tags = [pos for token, pos in pos_tags(tokens)]\n",
    "    conlltags = [(token, pos, ne) for token, pos, ne in zip(tokens, pos_tags, ne_tags)]\n",
    "    ne_tree = conlltags2tree(conlltags)\n",
    "    return ne_tree\n",
    "```\n",
    "\n",
    "```python\n",
    "#Parse named entities from tree\n",
    "def structure_ne(ne_tree):\n",
    "    ne = []\n",
    "    for subtree in ne_tree:\n",
    "        #if subtree is a noun chunk; NE != \"O\"\n",
    "        if type(subtree) == Tree: \n",
    "            ne_label = subtree.label()\n",
    "            ne_string = \" \".join([token for token, pos in subtree.leaves()])\n",
    "            ne.append((ne_string, ne_label))\n",
    "    return ne\n",
    "```\n",
    "\n",
    "```python\n",
    "#Process the whole tagging by calling the methods\n",
    "def main():\n",
    "    tokenized_text = process_text(r\"C:\\Users\\Daryl\\Desktop\\Data Analysis\\Stanford NER\\text1.txt\")\n",
    "    tagged = stanford_tagger(tokenized_text)\n",
    "```\n",
    "\n",
    "```Sample Output:\n",
    "[('``', 'O'),\n",
    " ('Singapore', 'LOCATION'),\n",
    " ('has', 'O'),\n",
    " ('also', 'O'),\n",
    " ('registered', 'O'),\n",
    " ('our', 'O'),\n",
    " ('concerns', 'O'),\n",
    " ('with', 'O'),\n",
    " ('the', 'O'),\n",
    " ('relevant', 'O'),\n",
    " ('US', 'LOCATION'),\n",
    " ('and', 'O'),\n",
    " ('China', 'LOCATION'),\n",
    " ('departments', 'O'),\n",
    " ('and', 'O'),\n",
    " ('is', 'O'),\n",
    " ('continuing', 'O'),\n",
    " ('to', 'O'),\n",
    " ('engage', 'O'),\n",
    " ('them', 'O'),\n",
    " (',', 'O'),\n",
    " (\"''\", 'O'),\n",
    " ('said', 'O'),\n",
    " ('the', 'O'),\n",
    " ('spokesperson', 'O'),\n",
    " (',', 'O'),\n",
    " ('who', 'O'),\n",
    " ('did', 'O'),\n",
    " ('not', 'O'),\n",
    " ('respond', 'O'),\n",
    " ('to', 'O'),\n",
    " ('a', 'O'),\n",
    " ('query', 'O'),\n",
    " ('on', 'O'),\n",
    " ('the', 'O'),\n",
    " ('number', 'O'),\n",
    " ('of', 'O'),\n",
    " ('firms', 'O'),\n",
    " ('affected', 'O'),\n",
    " ('.', 'O'),\n",
    " ('In', 'O'),\n",
    " ('January', 'O'),\n",
    " (',', 'O'),\n",
    " ('US', 'LOCATION'),\n",
    " ('President', 'O'),\n",
    " ('Donald', 'PERSON'),\n",
    " ('Trump', 'PERSON')]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
